<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>KĀEO Project - Frank Brockmann</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <nav><a href="index.html">← Back to Portfolio</a></nav>
    
    <header>
        <h1>Algorithmic Mediation of Linguistic Sovereignty</h1>
        <p>KĀEO Hawaiian Language Assessment AI Lab (2024-2025)</p>
    </header>
    
    <main>
        <h2>Research Question</h2>
        <p>How can AI-augmented workflows serve Hawaiian language assessment while preserving cultural authority and linguistic sovereignty? When computational systems analyze indigenous language test items, what safeguards ensure that algorithmic efficiency doesn't displace human expertise or reproduce colonial patterns of knowledge extraction?</p>
        
        <h2>Context & Challenge</h2>
        <p><strong>Program:</strong> Kaiapuni Assessment of Educational Outcomes (KĀEO), Hawaiʻi State Department of Education<br>
        <strong>Role:</strong> Assessment Consultant & AI Lab Co-Designer (2024-present)<br>
        <strong>Collaboration:</strong> Co-authored research paper with Pōhai Kūkea-Shultz (KĀEO Director)</p>
        
        <p>KĀEO is the only Hawaiian-medium assessment system in the world and the only native language assessment used for federal accountability in the US. All test content remains exclusively in ʻŌlelo Hawaiʻi to protect linguistic integrity. This creates a structural challenge: psychometric analysts are typically not Hawaiian speakers, while Hawaiian language educators are not trained psychometricians. This expertise gap historically created bottlenecks in identifying why test items performed poorly.</p>
        
        <h2>Methodology: AI Lab Design</h2>
        
        <h3>Design Principles</h3>
        <p>The AI Lab was organized as a design-based research project with iterative refinement. A critical principle was <strong>respecting the expertise and time of Hawaiian-language educators</strong>. Rather than asking content developers to synthesize extensive statistical reports across dozens of items, the workflow handles initial aggregation and pattern recognition, presenting interpretable summaries for cultural and linguistic review.</p>
        
        <h3>Ethical Framework</h3>
        <p>All work operated under the KĀEO AI Principles and Policy Framework (v4.0), which defines seven non-negotiable values: stewardship of student data, protection of linguistic integrity, equitable access, appropriate pedagogical integration, transparent communication, environmental responsibility, and <strong>the primacy of human expertise over technological efficiency</strong>.</p>
        
        <h3>Technical Architecture</h3>
        <p><strong>Tools:</strong> Google NotebookLM (document-grounded reasoning) and Claude 3.5 Sonnet (developer-facing interpretation)</p>
        
        <p><strong>Workflow Design:</strong></p>
        <ul>
            <li><strong>Tier 1:</strong> NotebookLM performs AI-assisted item diagnostics, generating structured analysis with strict citation to source documents</li>
            <li><strong>Tier 2:</strong> Cross-item synthesis identifies patterns across flagged items</li>
            <li><strong>Tier 3:</strong> Claude translates technical synthesis into developer-friendly interpretive briefs</li>
        </ul>
        
        <p><strong>Data Security:</strong> All work occurred in ephemeral, closed-system environments with no internet connectivity. Approximately 50-70 source documents were ingested (psychometric summaries, development manuals, technical reports) with all conversational history automatically deleted after each session.</p>
        
        <p><strong>Human Oversight:</strong> Three-layer review structure: Lab operators (technical configuration), psychometric expert (statistical accuracy), and cultural expert (linguistic integrity and Hawaiian educational values). Every AI-generated claim required explicit source citation.</p>
        
        <h3>Solving the Interpretability Gap</h3>
        <p>Within the secure NotebookLM environment, English paraphrases of Hawaiian items served as temporary analytic artifacts—allowing psychometric reasoning about item structure without publicly translating or altering Hawaiian source text. This created, for the first time, a mechanism for cross-language analysis that preserved linguistic sovereignty while enabling technical review.</p>
        
        <h2>Results</h2>
        <p>The Round 2 implementation (October 2025) analyzed 58 flagged items across Hawaiian Language Arts, Mathematics, and Science. Six interpretive briefs identified systemic design issues including linguistic ambiguity, Depth-of-Knowledge misalignment, and structural overload in test items. The workflow demonstrated that AI could accelerate pattern detection across large item sets while maintaining human authority over all interpretive decisions.</p>
        
        <h2>Computational Media Analysis</h2>
        
        <h3>Redefining "Human-in-the-Loop"</h3>
        <p>Traditional psychometric review separates technical and linguistic expertise by geography and language barriers. This project redefined human-in-the-loop as <strong>multi-expert collaboration through AI mediation</strong>. The tools provided rapid aggregation and translation, allowing non-Hawaiian-speaking analysts to participate meaningfully while keeping source content protected.</p>
        
        <h3>Power Dynamics in Algorithmic Analysis</h3>
        <p>When computational systems analyze indigenous language, who holds interpretive authority? The KĀEO workflow explicitly positioned AI outputs as provisional models requiring expert validation—cultural review identified moments where algorithmic analysis missed figurative depth, reminding us that measurement of ʻŌlelo Hawaiʻi requires human cultural context that algorithms cannot replicate.</p>
        
        <h3>Technology as Workflow Component, Not Replacement</h3>
        <p>The system's success arose not from automation but from bounded structure: secure environments, document-grounded reasoning, and cultural oversight. This reframes AI not as autonomous scorer or author, but as specialized assistant embedded in a chain of accountable humans—what might be called "augmentative intelligence" rather than "artificial intelligence."</p>
        
        <h2>Theoretical Grounding</h2>
        <p>This work engages questions of <strong>algorithmic colonialism</strong> (how computational systems can reproduce or resist patterns of cultural extraction), <strong>data sovereignty</strong> in indigenous contexts, <strong>distributed cognition</strong> across human-AI systems, and the <strong>politics of computational mediation</strong> in culturally specific knowledge domains.</p>
        
        <h2>Publication Status</h2>
        <p>Co-authored research paper with Pōhai Kūkea-Shultz: "Bridging Psychometric and Content Development Practices with AI: A Community-Based Workflow for Augmenting Hawaiian Language Assessments." Prepared for arXiv submission (November 2025).</p>
    </main>
    
    <footer>
        <p><a href="index.html">← Back to Portfolio</a></p>
    </footer>
</body>
</html>
